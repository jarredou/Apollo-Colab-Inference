{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/Q5Q811R5YI)  \n",
        "# Apollo-Colab-Inference [![Open In Github](https://img.shields.io/badge/github-code-green)](https://github.com/jarredou/Apollo-Colab-Inference/)  \n",
        "\n",
        "\n",
        "*Original work [Apollo: Band-sequence Modeling for High-Quality Music Restoration in Compressed Audio](https://github.com/JusperLee/Apollo)*  \n",
        "\n",
        "The model was trained to restore/enhance lossy mp3 audio with bitrate <= 128 kbps.  \n",
        "<br>\n",
        "___  \n",
        "*changelog:*\n",
        "   \n",
        "<font size=2>**v0.2**  \n",
        "<font size=2>- added overlap feature  \n",
        "<font size=2>- new inference.py created for easier local CLI use  \n",
        "\n",
        "<font size=2>**v0.1**  \n",
        "<font size=2>- added chunking for long audio inputs  \n",
        "<font size=2>- ~~added \"dual mono\" processing for stereo audio input (processing each channel independently)~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8NuwnC--VPO4"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "#@markdown #Install\n",
        "%cd /content/\n",
        "!git clone https://github.com/JusperLee/Apollo.git && cd Apollo\n",
        "\n",
        "!mkdir /content/Apollo/model\n",
        "%cd /content/Apollo/model\n",
        "!wget https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin\n",
        "\n",
        "!rm -rf '/content/Apollo/inference.py'\n",
        "%cd /content/Apollo\n",
        "!wget 'https://raw.githubusercontent.com/jarredou/Apollo-Colab-Inference/main/inference.py'\n",
        "\n",
        "!pip install omegaconf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xFqIYcKxVXyd"
      },
      "outputs": [],
      "source": [
        "%cd /content/Apollo\n",
        "#@markdown #Inference\n",
        "input_file_path = '/content/input.wav' #@param {type:\"string\"}\n",
        "output_file_path = '/content/output.wav' #@param {type:\"string\"}\n",
        "chunk_size = 3 #@param {type:\"slider\", min:3, max:25, step:1}\n",
        "overlap = 2 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "!python inference.py \\\n",
        "    --in_wav '{input_file_path}' \\\n",
        "    --out_wav '{output_file_path}' \\\n",
        "    --chunk_size {chunk_size} \\\n",
        "    --overlap {overlap}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
