{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-_VkjEtMvc5"
      },
      "source": [
        "[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/Q5Q811R5YI)  \n",
        "# Apollo-Colab-Inference [![Open In Github](https://img.shields.io/badge/github-code-green)](https://github.com/jarredou/Apollo-Colab-Inference/)  \n",
        "\n",
        "\n",
        "*Original work [Apollo: Band-sequence Modeling for High-Quality Music Restoration in Compressed Audio](https://github.com/JusperLee/Apollo)*  \n",
        "\n",
        "The model was trained to restore/enhance lossy mp3 audio with bitrate <= 128 kbps.  \n",
        "<br>\n",
        "___  \n",
        "*changelog:*\n",
        "\n",
        "<font size=2>**v0.5**  \n",
        "<font size=2>- added: lew's universal model  \n",
        "\n",
        "<font size=2>**v0.4**  \n",
        "<font size=2>- added: config loader  \n",
        "<font size=2>- added: lew's separated vocals enhancer v2 beta\n",
        "\n",
        "<font size=2>**v0.3**  \n",
        "<font size=2>- lew's separated vocals enhancer model added\n",
        "\n",
        "<font size=2>**v0.2**  \n",
        "<font size=2>- added overlap feature  \n",
        "<font size=2>- new inference.py created for easier local CLI use  \n",
        "\n",
        "<font size=2>**v0.1**  \n",
        "<font size=2>- added chunking for long audio inputs  \n",
        "<font size=2>- ~~added \"dual mono\" processing for stereo audio input (processing each channel independently)~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8NuwnC--VPO4"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "#@markdown #Install\n",
        "%cd /content/\n",
        "!git clone https://github.com/JusperLee/Apollo.git && cd Apollo\n",
        "\n",
        "!mkdir /content/Apollo/model\n",
        "%cd /content/Apollo/model\n",
        "!wget 'https://huggingface.co/JusperLee/Apollo/resolve/main/pytorch_model.bin'\n",
        "!wget 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model.ckpt'\n",
        "!wget 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/apollo_model_v2.ckpt'\n",
        "!wget 'https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/apollo_model_uni.ckpt'\n",
        "\n",
        "%cd /content/Apollo/configs\n",
        "!wget 'https://huggingface.co/jarredou/lew_apollo_vocal_enhancer/resolve/main/config_apollo_vocal.yaml'\n",
        "!wget 'https://github.com/deton24/Lew-s-vocal-enhancer-for-Apollo-by-JusperLee/releases/download/uni/config_apollo_uni.yaml'\n",
        "\n",
        "!rm -rf '/content/Apollo/inference.py'\n",
        "%cd /content/Apollo\n",
        "!wget 'https://raw.githubusercontent.com/jarredou/Apollo-Colab-Inference/main/inference.py'\n",
        "\n",
        "!pip install omegaconf ml_collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xFqIYcKxVXyd"
      },
      "outputs": [],
      "source": [
        "%cd /content/Apollo\n",
        "#@markdown #Inference\n",
        "#@markdown For the universal model set *chunk_size* above to 19, for all other models set it to 25\n",
        "input_file_path = '/content/input.wav' #@param {type:\"string\"}\n",
        "output_file_path = '/content/output.wav' #@param {type:\"string\"}\n",
        "model = 'Lew Universal Lossy Enhancer' #@param ['MP3 Enhancer', 'Lew Vocal Enhancer', 'Lew Vocal Enhancer v2 (beta)', 'Lew Universal Lossy Enhancer']\n",
        "chunk_size = 19 #@param {type:\"slider\", min:3, max:25, step:1}\n",
        "overlap = 2 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "if model == 'MP3 Enhancer':\n",
        "    ckpt = '/content/Apollo/model/pytorch_model.bin'\n",
        "    config = 'configs/apollo.yaml'\n",
        "if model == 'Lew Vocal Enhancer':\n",
        "    ckpt = '/content/Apollo/model/apollo_model.ckpt'\n",
        "    config = 'configs/apollo.yaml'\n",
        "if model == 'Lew Vocal Enhancer v2 (beta)':\n",
        "    ckpt = '/content/Apollo/model/apollo_model_v2.ckpt'\n",
        "    config = 'configs/config_apollo_vocal.yaml'\n",
        "if model == 'Lew Universal Lossy Enhancer':\n",
        "    ckpt = '/content/Apollo/model/apollo_model_uni.ckpt'\n",
        "    config = 'configs/config_apollo_uni.yaml'\n",
        "\n",
        "!python inference.py \\\n",
        "    --in_wav '{input_file_path}' \\\n",
        "    --out_wav '{output_file_path}' \\\n",
        "    --chunk_size {chunk_size} \\\n",
        "    --overlap {overlap} \\\n",
        "    --ckpt '{ckpt}' \\\n",
        "    --config '{config}'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
